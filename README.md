

## Clustering Analysis with K-Means and K-Medoids on the Wine Dataset

### Purpose:
This lab explores clustering techniques using the Wine Dataset from `sklearn`. The goal was to apply and compare two clustering algorithms, **K-Means** and **K-Medoids**, to analyze their performance in grouping the wine samples based on their features. By evaluating both algorithms using **Silhouette Score** and **Adjusted Rand Index (ARI)**, we aimed to determine which clustering method produced more well-defined and accurate clusters. Additionally, visualizations were created to compare the cluster shapes and positioning generated by both algorithms.

### Key Insights:
- **K-Means** produced better-defined clusters compared to **K-Medoids**. The Silhouette Score for K-Means (0.28) was higher than that of K-Medoids (0.27), indicating that the clusters formed by K-Means were more compact and distinct. The **Adjusted Rand Index (ARI)** for K-Means was 0.90, showing a stronger alignment with the true class labels (wine types), compared to the ARI of 0.74 for K-Medoids.
- **K-Means** performed well because the clusters were relatively compact and well-separated, making it a suitable choice for this dataset. On the other hand, **K-Medoids** was more sensitive to noise and less effective in capturing clear cluster boundaries. However, K-Medoids is more robust when the dataset contains outliers, which could make it a better choice for certain types of data.
- Visualization of the clusters using **PCA** (Principal Component Analysis) revealed that K-Means formed spherical clusters, while K-Medoids showed more irregular cluster shapes.

### Challenges and Decisions:
- **Data Scaling**: Ensuring proper scaling of the features was crucial. We standardized the dataset using **z-score normalization** to ensure that each feature contributed equally to the clustering process.
- **Choosing Initial Medoids**: In K-Medoids, selecting the initial medoids was a challenge. We arbitrarily selected initial medoids from the dataset, but this could be improved with optimization techniques for better results.
- **Clustering Evaluation**: The primary challenge was evaluating the quality of clustering. Using **Silhouette Score** and **Adjusted Rand Index** provided a quantitative measure, but visual inspection was also crucial to assess cluster integrity.
